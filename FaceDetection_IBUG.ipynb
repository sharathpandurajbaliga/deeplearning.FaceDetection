{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharathpandurajbaliga/deeplearning.FaceDetection/blob/main/FaceDetection_IBUG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfXTZWD5kecw"
      },
      "source": [
        "Connect to the google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQLD40q7kQa9",
        "outputId": "588042cf-3fc4-45c2-9916-e845efcd021c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGODT_7QfyvM"
      },
      "source": [
        "Check if GPU available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW39zzJcfxmq",
        "outputId": "2b18e87e-40f8-42a0-bff5-868216962cdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul 16 01:00:39 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VWxFvO2lX-v"
      },
      "source": [
        "All imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fXrirq67k818"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import json\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import ast\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import csv\n",
        "from random import seed\n",
        "from random import randint\n",
        "seed(1)\n",
        "import math\n",
        "import shutil\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.optim as optim\n",
        "import xml.etree.ElementTree as ET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_DFZD9PdWS3"
      },
      "source": [
        "Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-lrlIlkYlcrQ"
      },
      "outputs": [],
      "source": [
        "class dataset_util(Dataset):\n",
        "  def __init__(self, data_basedir, traindir, label_path, transform):\n",
        "    self.data_basedir = data_basedir\n",
        "    self.traindir = traindir\n",
        "    self.label_path = label_path\n",
        "    self.transform = transform\n",
        "    self.label_ids = self.__iterate_through_labels()\n",
        "\n",
        "  def __iterate_through_images(self, dirs):\n",
        "    image_ids = []\n",
        "    for dir in dirs:\n",
        "      image_path = os.path.join(self.data_basedir, dir)\n",
        "      for img in glob.glob(image_path + \"/*.jpg\"):\n",
        "          image_ids.append(img)\n",
        "    return image_ids\n",
        "\n",
        "  def __iterate_through_labels(self):\n",
        "    label_ids = {}\n",
        "    tree = ET.parse(os.path.join(self.data_basedir, self.label_path))\n",
        "    root = tree.getroot()\n",
        "    count = 0\n",
        "    for image in root.find('images'):\n",
        "      #boxElement = box.getElementsByTagName('box')[0]\n",
        "      #print(image.attrib)\n",
        "      box = image.find('box')\n",
        "      image_width = int(image.attrib['width'])\n",
        "      image_height = int(image.attrib['height'])\n",
        "      scale_w = 400/image_width\n",
        "      scale_h = 400/image_height\n",
        "      top = int(int(box.attrib['top'])*scale_h)\n",
        "      left = int(int(box.attrib['left'])*scale_w)\n",
        "      width = int(int(box.attrib['width'])*scale_w)\n",
        "      height = int(int(box.attrib['height'])*scale_h)\n",
        "      label_ids[count] = [image.attrib['file'], top, left, width, height]\n",
        "      count = count + 1\n",
        "    return label_ids\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    label_list = self.label_ids[idx]\n",
        "    img = self.__load_image(os.path.join(self.data_basedir, label_list[0]))\n",
        "    tensor_image = self.transform(img)\n",
        "    label = self.__get_label(label_list)\n",
        "    return tensor_image, label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label_ids.keys())\n",
        "  \n",
        "  def __load_image(self, image_path):\n",
        "    image_path = os.path.join(self.data_basedir, image_path)\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (400,400)) # INTER_AREA\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return img\n",
        "  \n",
        "  def __get_label(self, label_list):\n",
        "    return np.array(label_list[1:])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpOMUKGAkKnT"
      },
      "source": [
        "Face Detection "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BkEPinOgkOdo"
      },
      "outputs": [],
      "source": [
        "class face_detection:\n",
        "  def __init__(self, train_loader, valid_loader, model, criterion, optimizer, epochs, model_to_save):\n",
        "    self.criterion = criterion\n",
        "    self.optimizer = optimizer\n",
        "    self.model = model\n",
        "    self.epochs = epochs\n",
        "    self.train_on_gpu = torch.cuda.is_available()\n",
        "    self.model_to_save = model_to_save\n",
        "    if self.train_on_gpu:\n",
        "      self.model.cuda()\n",
        "\n",
        "    self.train_loader = train_loader\n",
        "    self.valid_loader = valid_loader\n",
        "    return \n",
        "\n",
        "  def train(self):\n",
        "    # track change in validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    print(\"Starting the train...\")\n",
        "    for epoch in range(1, self.epochs+1):\n",
        "\n",
        "        # keep track of training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        self.model.train()\n",
        "        for data, target in train_loader:\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if self.train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            # clear the gradients of all optimized variables\n",
        "            self.optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = self.model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = self.criterion(output, target.float())\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            self.optimizer.step()\n",
        "            # update training loss\n",
        "            train_loss += loss.item()*data.size(0)\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        count = 0\n",
        "        self.model.eval()\n",
        "        for data, target in valid_loader:\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if self.train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = self.model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = self.criterion(output, target.float())\n",
        "            # update average validation loss \n",
        "            valid_loss += loss.item()*data.size(0)\n",
        "        \n",
        "        # calculate average losses\n",
        "        train_loss = train_loss/len(train_loader.dataset)\n",
        "        valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "            \n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, train_loss, valid_loss))\n",
        "        \n",
        "        # save model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "            torch.save(self.model.state_dict(), self.model_to_save)\n",
        "            valid_loss_min = valid_loss\n",
        "    return\n",
        "\n",
        "  def test(self, model_path):\n",
        "    self.model.load_state_dict(torch.load(model_path))\n",
        "    # track test loss\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "\n",
        "    self.model.eval()\n",
        "    # iterate over test data\n",
        "    for data, target in test_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "\n",
        "        if self.train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = self.model(data)\n",
        "\n",
        "        # calculate the batch loss\n",
        "        loss = self.criterion(output, target)\n",
        "\n",
        "        # update test loss \n",
        "        test_loss += loss.item()*data.size(0)\n",
        "\n",
        "    # average test loss\n",
        "    test_loss = test_loss/len(test_loader.dataset)\n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "    return\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlyRQ7pKXTmo"
      },
      "source": [
        "Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C5c31vBTXUzS"
      },
      "outputs": [],
      "source": [
        "class myResNetModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(myResNetModel, self).__init__()\n",
        "    self.model = models.resnet18()\n",
        "    self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    self.model.fc = nn.Linear(self.model.fc.in_features, 4)\n",
        "    return \n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.model(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfASyxppXpde"
      },
      "source": [
        "Code starts running from here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH1tIxzvXtYC",
        "outputId": "64376b20-eec7-4028-a705-4b84d0c44dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Images:  6666\n"
          ]
        }
      ],
      "source": [
        "data_transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/MyProjects/300W_FaceProject/ibug_300W_large_face_landmark_dataset\"\n",
        "train_dir = [\"afw\",\"helen\", \"ibug\", \"lfpw\"]\n",
        "train_label = \"labels_ibug_300W_train.xml\"\n",
        "test_label = \"labels_ibug_300W_test.xml\"\n",
        "\n",
        "train_data = dataset_util(base_dir, train_dir, train_label, data_transform)\n",
        "test_data = dataset_util(base_dir, train_dir, test_label, data_transform)\n",
        "\n",
        "# print out some data stats\n",
        "train_landmarks_length = len(train_data)\n",
        "print('Total Number of Images: ', train_landmarks_length )\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "num_train = len(train_data)\n",
        "num_test = len(test_data)\n",
        "train_indices = list(range(num_train))\n",
        "test_indices = list(range(num_test))\n",
        "np.random.shuffle(train_indices)\n",
        "\n",
        "train_split = int(np.floor(0.85 * num_train))\n",
        "valid_split = int(num_train - train_split)\n",
        "\n",
        "train_idx = train_indices[:train_split]\n",
        "valid_idx = train_indices[train_split:]\n",
        "test_idx = test_indices\n",
        "\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# prepare data loaders (combine dataset and sampler)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,sampler=valid_sampler, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,sampler=test_sampler, num_workers=num_workers)\n",
        "\n",
        "model = myResNetModel()\n",
        "epochs = 100\n",
        "\n",
        "# specify loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "face_detection_util = face_detection(train_loader, valid_loader, model, criterion, optimizer, epochs, os.path.join(base_dir,\"face_detector_gray_400_400.pt\"))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "face_detection_util.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBb8xjD5n1gd",
        "outputId": "c8ca0249-dcac-4505-a614-1d7684936723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the train...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfTIXMqfXmeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b296b1-7ab7-412f-be1b-81774438a177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 12.835593\n",
            "\n"
          ]
        }
      ],
      "source": [
        "face_detection_util.test(os.path.join(base_dir,\"face_detector_gray_400_400.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6ytMm1aUpC-g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "FaceDetection_IBUG.ipynb",
      "provenance": [],
      "mount_file_id": "195VJw6feKS93K3jeELE7NgEk15tZHbYR",
      "authorship_tag": "ABX9TyNZYtX725eA4YrC7LeH2MOz",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}